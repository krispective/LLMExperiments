{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:41:35.007151Z",
     "iopub.status.busy": "2024-05-28T12:41:35.006750Z",
     "iopub.status.idle": "2024-05-28T12:41:56.033544Z",
     "shell.execute_reply": "2024-05-28T12:41:56.032506Z",
     "shell.execute_reply.started": "2024-05-28T12:41:35.007119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 12:41:44.535164: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-28 12:41:44.535267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-28 12:41:44.702885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d1114c84eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:41:56.036551Z",
     "iopub.status.busy": "2024-05-28T12:41:56.035526Z",
     "iopub.status.idle": "2024-05-28T12:43:19.130563Z",
     "shell.execute_reply": "2024-05-28T12:43:19.129509Z",
     "shell.execute_reply.started": "2024-05-28T12:41:56.036514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbbc237c3064f069e792ad303184216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8832480219c14d94b81dbb3b6a5b2196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff7aa5185f54b10812529c77140ab0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0d2fe5759242ceb5d9d170595ec4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc7d350a074a5c8a21e0986bc24545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0457b1627a243999bf6874185d732bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aabba384274bcba1dfc6041b28c074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b9751e393847388e82ad9bdc864a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cc465968d346a2acba934034647d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528a50745eb14116b13818eaa5ecb94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ce4f6090154c21bce3a83a4a362106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b6a0922e5f4658bc70ad0c2ca5ea6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c320a6d10f412a923ae136fefd3bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0482e0eebc2b42468bbd786e068e3a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To evaluate the summarization provided, we will consider several metrics:\n",
      "\n",
      "\n",
      "1. **Coverage**: The summary should capture the main points of the original text. In this case, the summary correctly identifies the key elements: the National Commercial Bank's acquisition of Samba Financial Group, the valuation of the deal, and the resulting size of the new entity.\n",
      "\n",
      "\n",
      "2. **Conciseness**: The summary should be brief and to the point. The provided summary is concise, containing only the essential information without unnecessary details.\n",
      "\n",
      "\n",
      "3. **Fluency**: The summary should read smoothly and be grammatically correct. The given summary is well-structured and free of errors, demonstrating good fluency.\n",
      "\n",
      "\n",
      "4. **Accuracy**: The summary must accurately reflect the content of the original text. The numbers and facts presented in the summary are consistent with the original text, such as the 3.5% premium and the total assets of the new bank.\n",
      "\n",
      "\n",
      "5. **Coherence and Cohesion**: The summary should be logically organized and the sentences should be connected well. The summary provided maintains a logical flow and uses appropriate connectors to ensure coherence.\n",
      "\n",
      "\n",
      "6. **Informativeness**: The summary should inform the reader about the main outcomes of the event. The summary successfully informs about the acquisition, the financial details, and the significance of the new bank in the Gulf region.\n",
      "\n",
      "\n",
      "Based on these metrics, the summarization performed by the LLM can be considered effective and accurate.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Evaluate the following summarization performend by an LLM. Input is enclosed within triple slashes and output is enclosed within triple equals.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"///National Commercial Bank (NCB), Saudi Arabia’s largest lender by assets, agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework agreement in June.The offer is a 3.5% premium to Samba’s Oct. 8 closing price of 27.50 riyals and about 24% higher than the level the shares traded at before the talks were made public. Bloomberg News first reported the merger discussions.The new bank will have total assets of more than $220 billion, creating the Gulf region’s third-largest lender. The entity’s $46 billion market capitalization nearly matches that of Qatar National Bank QPSC, which is still the Middle East’s biggest lender with about $268 billion of assets./// ===Saudi bank to pay a 3.5% premium to Samba share price. Gulf region’s third-largest lender will have total assets of $220 billion===\"},\n",
    "    {\"role\": \"user\", \"content\": \"Use evaluation metrics for summarization activity and prove your claims\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T19:26:40.215423Z",
     "iopub.status.busy": "2024-05-22T19:26:40.215080Z",
     "iopub.status.idle": "2024-05-22T19:26:40.221507Z",
     "shell.execute_reply": "2024-05-22T19:26:40.220581Z",
     "shell.execute_reply.started": "2024-05-22T19:26:40.215386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' To solve the equation 2x + 3 = 7, you need to isolate the variable x. Here are the steps:\\n\\n1. Subtract 3 from both sides of the equation to get rid of the +3 on the left side. This gives you: 2x = 7 - 3, which simplifies to 2x = 4.\\n\\n2. Now, divide both sides of the equation by 2 to solve for x. This gives you: x = 4 / 2, which simplifies to x = 2.\\n\\nSo, the solution to the equation 2x + 3 = 7 is x = 2.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:33:44.868101Z",
     "iopub.status.busy": "2024-05-28T12:33:44.867561Z",
     "iopub.status.idle": "2024-05-28T12:33:45.261536Z",
     "shell.execute_reply": "2024-05-28T12:33:45.260691Z",
     "shell.execute_reply.started": "2024-05-28T12:33:44.868061Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/kaggle/input/testkk/Conversation_intent - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:33:49.399612Z",
     "iopub.status.busy": "2024-05-28T12:33:49.399195Z",
     "iopub.status.idle": "2024-05-28T12:33:49.420910Z",
     "shell.execute_reply": "2024-05-28T12:33:49.419659Z",
     "shell.execute_reply.started": "2024-05-28T12:33:49.399578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\\r\\n  \"conversation\": [\\r\\n    {\\r\\n      \"cu...</td>\n",
       "      <td>Plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\\r\\n  \"conversation\": [\\r\\n    {\\r\\n      \"cu...</td>\n",
       "      <td>Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n{\\n  \"conversation\": [\\n    {\\n      \"custom...</td>\n",
       "      <td>Billing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Conversation   Intent\n",
       "0  {\\r\\n  \"conversation\": [\\r\\n    {\\r\\n      \"cu...     Plan\n",
       "1  {\\r\\n  \"conversation\": [\\r\\n    {\\r\\n      \"cu...  Network\n",
       "2  \\n{\\n  \"conversation\": [\\n    {\\n      \"custom...  Billing"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:37:29.219688Z",
     "iopub.status.busy": "2024-05-28T12:37:29.218892Z",
     "iopub.status.idle": "2024-05-28T12:37:29.224639Z",
     "shell.execute_reply": "2024-05-28T12:37:29.223596Z",
     "shell.execute_reply.started": "2024-05-28T12:37:29.219651Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def get_json(text):\n",
    "    text = text.replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\"\\'\",\"\")\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:37:48.332279Z",
     "iopub.status.busy": "2024-05-28T12:37:48.331629Z",
     "iopub.status.idle": "2024-05-28T12:37:48.337664Z",
     "shell.execute_reply": "2024-05-28T12:37:48.336874Z",
     "shell.execute_reply.started": "2024-05-28T12:37:48.332242Z"
    }
   },
   "outputs": [],
   "source": [
    "cc = get_json(df.loc[0,\"Conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:45:05.771258Z",
     "iopub.status.busy": "2024-05-28T12:45:05.770508Z",
     "iopub.status.idle": "2024-05-28T12:45:05.778335Z",
     "shell.execute_reply": "2024-05-28T12:45:05.777223Z",
     "shell.execute_reply.started": "2024-05-28T12:45:05.771215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"customer\": \"I bought Unlimited 5plus plan and iPhone 15 Pro because they were saying get 65\\\\u201d inch 4K TV on us. But now when I try to claim the offer it says the offer has expired. If I\\\\u2019m not getting the TV then what\\\\u2019s the point of getting the Unlimited 5plus plan and new device? Please, if anyone from Verizon is reading this, help me to claim my offer.\"}, {\"agent\": \"Hello! I understand your frustration. Let me look into this for you. Can you please provide me with your order number and the date of purchase?\"}, {\"customer\": \"Sure, my order number is 123456789, and I purchased the plan and device on May 10th.\"}, {\"agent\": \"Thank you for the details. Please hold on for a moment while I check your order and the offer details.\"}, {\"agent\": \"I see that your purchase was indeed within the promotional period. It seems like there might be an issue with the system not recognizing your eligibility. Let me escalate this to our promotions team to resolve it.\"}, {\"customer\": \"I appreciate that. How long will it take to get this resolved?\"}, {\"agent\": \"The promotions team typically responds within 24-48 hours. I will ensure they prioritize your case and keep you updated on the progress.\"}, {\"customer\": \"Thank you. I hope this can be sorted out quickly. I was really looking forward to the TV.\"}, {\"agent\": \"Youre welcome! We will do our best to resolve this as soon as possible. Is there anything else I can assist you with today?\"}, {\"customer\": \"No, thats all for now. Thanks for your help.\"}, {\"agent\": \"Anytime! Have a great day, and we\\\\u2019ll be in touch soon.\"}]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(cc['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:49:03.929770Z",
     "iopub.status.busy": "2024-05-28T12:49:03.929364Z",
     "iopub.status.idle": "2024-05-28T12:49:03.936095Z",
     "shell.execute_reply": "2024-05-28T12:49:03.935030Z",
     "shell.execute_reply.started": "2024-05-28T12:49:03.929739Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_message = \"\"\"Rubric to Assess if the Conversation is About a Billing Issue\n",
    "\n",
    "Mention of Charges: The conversation includes a discussion about charges on the customer's account.\n",
    "\n",
    "Score 1 if present.\n",
    "Billing Cycle References: The conversation references billing cycles or periods.\n",
    "\n",
    "Score 1 if present.\n",
    "Credit or Refunds: The conversation involves the customer inquiring about or mentioning credits or refunds.\n",
    "\n",
    "Score 1 if present.\n",
    "Invoice or Bill Confusion: The customer expresses confusion or dissatisfaction with their invoice or bill.\n",
    "\n",
    "Score 1 if present.\n",
    "Payment Issues: The customer mentions issues with making a payment or the payment process.\n",
    "\n",
    "Score 1 if present.\n",
    "Discrepancies in Amounts: The conversation includes a discussion about discrepancies in billed amounts versus expected amounts.\n",
    "\n",
    "Score 1 if present.\n",
    "Overcharges or Unrecognized Charges: The customer mentions being overcharged or having unrecognized charges on their bill.\n",
    "\n",
    "Score 1 if present.\n",
    "Promotions or Discounts Not Applied: The customer mentions that a promotional offer or discount has not been applied to their bill.\n",
    "\n",
    "Score 1 if present.\n",
    "Recurring Charges: The conversation includes issues with recurring charges or subscriptions.\n",
    "\n",
    "Score 1 if present.\n",
    "Resolution Timeline: The agent discusses a timeline or process for resolving a billing-related issue.\n",
    "\n",
    "Score 1 if present.\n",
    "Total Score:\n",
    "\n",
    "The conversation is about a billing issue if it scores 5 or higher out of 10.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:00:06.224909Z",
     "iopub.status.busy": "2024-05-28T13:00:06.223996Z",
     "iopub.status.idle": "2024-05-28T13:00:06.231528Z",
     "shell.execute_reply": "2024-05-28T13:00:06.230498Z",
     "shell.execute_reply.started": "2024-05-28T13:00:06.224874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"customer\": \"I purchased a new iPhone 15 Pro Max and added a new line on Dec 31st, 2023, through Verizon by speaking with one of the agents over the phone. The purchase was made with the understanding that I would receive a $1000 trade-in credit ($27.77 per month) by sending my Samsung S7 phone as part of a Thanksgiving promotional offer. However, despite numerous attempts to resolve this matter, the credit has not been applied to my account.\"}, {\"customer\": \"Over the past month, I have engaged with at least 25 different Verizon agents over the phone and chat, spending around 30 hours attempting to address this issue. Each representative assured me that the credit would be processed in five days or in the next billing cycle, but it has yet to materialize. Sometimes I was told I would receive a callback, which never happens, and sometimes agents disconnect calls after staying on the call for hours.\"}, {\"agent\": \"Im really sorry to hear about the trouble youve been experiencing. Let me help you get this resolved. Can you please provide me with your account number and any reference numbers related to your previous interactions?\"}, {\"customer\": \"My account number is 456789123. Unfortunately, I dont have any reference numbers, but I can provide you with the details of my trade-in.\"}, {\"agent\": \"Thank you. Please hold on for a moment while I review your account and the trade-in details.\"}, {\"agent\": \"I see the details of your trade-in and the promotional offer. It appears that there was an error in processing your trade-in credit. I will escalate this to our promotions and billing team to ensure the credit is applied immediately.\"}, {\"customer\": \"I appreciate that. How long will it take to get this resolved? Ive already waited so long.\"}, {\"agent\": \"I understand your frustration. I will mark this as urgent, and the team should resolve it within 48 hours. I will also personally follow up to ensure it is completed and keep you updated.\"}, {\"customer\": \"Thank you. I hope this finally gets sorted out.\"}, {\"agent\": \"Youre welcome. We will do everything we can to ensure this is resolved quickly. Is there anything else I can assist you with today?\"}, {\"customer\": \"No, thats all for now. Thanks for your help.\"}, {\"agent\": \"Anytime. Have a great day, and we will be in touch soon.\"}]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(get_json(df.loc[2,\"Conversation\"])[\"conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:02:05.220369Z",
     "iopub.status.busy": "2024-05-28T13:02:05.219960Z",
     "iopub.status.idle": "2024-05-28T13:02:36.271247Z",
     "shell.execute_reply": "2024-05-28T13:02:36.270242Z",
     "shell.execute_reply.started": "2024-05-28T13:02:05.220340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mention of Charges: The customer discusses an expected $1000 trade-in credit, which is a financial charge, so this is present. Score: 1\n",
      "\n",
      "Billing Cycle References: The customer mentions the trade-in credit would be applied in the next billing cycle, so this is present. Score: 1\n",
      "\n",
      "Credit or Refunds: The customer is expecting a $1000 credit for the trade-in, which is a credit, so this is present. Score: 1\n",
      "\n",
      "Invoice or Bill Confusion: The customer expresses confusion about the credit not being applied to their bill, so this is present. Score: 1\n",
      "\n",
      "Payment Issues: There is no direct mention of payment issues in this conversation, so this is not present. Score: 0\n",
      "\n",
      "Discrepancies in Amounts: The customer is expecting a $1000 credit but has not received it, indicating a discrepancy in amounts, so this is present. Score: 1\n",
      "\n",
      "Overcharges or Unrecognized Charges: The customer is not discussing overcharges or unrecognized charges, but rather an expected credit, so this is not present. Score: 0\n",
      "\n",
      "Promotions or Discounts Not Applied: The customer mentions a promotional offer for the trade-in credit, so this is present. Score: 1\n",
      "\n",
      "Recurring Charges: There is no mention of recurring charges in this conversation, so this is not present. Score: 0\n",
      "\n",
      "Resolution Timeline: The agent promises to escalate the issue and resolve it within 48 hours, so this is present. Score: 1\n",
      "\n",
      "Total Score: 7 out of 10. The conversation is about a billing issue as it scores 7 or higher out of 10.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": assistant_message},\n",
    "    {\"role\": \"assistant\", \"content\": json.dumps(get_json(df.loc[2,\"Conversation\"])[\"conversation\"])},\n",
    "    {\"role\": \"user\", \"content\": \"Give your reasoning and add points to finally end the response with a score. Your response should be in text giving a 1 or 0 for each rubric.\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T12:53:36.813555Z",
     "iopub.status.busy": "2024-05-28T12:53:36.813162Z",
     "iopub.status.idle": "2024-05-28T12:53:36.820022Z",
     "shell.execute_reply": "2024-05-28T12:53:36.818956Z",
     "shell.execute_reply.started": "2024-05-28T12:53:36.813523Z"
    }
   },
   "outputs": [],
   "source": [
    "subscription_plan = \"\"\"\n",
    "Rubric to Assess if the Conversation is About a Subscription Plan Clarification Issue\n",
    "\n",
    "Subscription Plan Details: The conversation includes a discussion about the details of the customer's subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Plan Features: The customer inquires about or mentions specific features included in their subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Plan Pricing: The conversation involves clarifying the pricing of the subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Plan Limitations: The customer asks about or mentions limitations or restrictions of their subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Upgrade or Downgrade Options: The conversation includes a discussion about options to upgrade or downgrade the subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Contract Terms: The customer asks about or mentions the terms of the contract associated with their subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Data or Usage Limits: The conversation involves clarifying data or usage limits included in the subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Plan Comparison: The customer asks for a comparison between different subscription plans.\n",
    "\n",
    "Score 1 if present.\n",
    "Billing Cycle Related to Plan: The conversation includes clarifying how billing cycles work in relation to the subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Promotional Offers: The customer inquires about promotional offers or discounts associated with their subscription plan.\n",
    "\n",
    "Score 1 if present.\n",
    "Total Score:\n",
    "\n",
    "The conversation is about a subscription plan clarification issue if it scores 5 or higher out of 10.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:03:16.061633Z",
     "iopub.status.busy": "2024-05-28T13:03:16.061269Z",
     "iopub.status.idle": "2024-05-28T13:03:41.576158Z",
     "shell.execute_reply": "2024-05-28T13:03:41.575128Z",
     "shell.execute_reply.started": "2024-05-28T13:03:16.061596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Subscription Plan Details: The customer discusses their subscription plan, specifically mentioning the \"Unlimited 5plus plan,\" which indicates the presence of this detail. Score: 1\n",
      "\n",
      "- Plan Features: The customer does not explicitly mention any specific features of their subscription plan. Score: 0\n",
      "\n",
      "- Plan Pricing: The customer does not discuss the pricing of their subscription plan. Score: 0\n",
      "\n",
      "- Plan Limitations: The customer does not mention any limitations or restrictions of their subscription plan. Score: 0\n",
      "\n",
      "- Upgrade or Downgrade Options: The customer does not discuss any options to upgrade or downgrade their subscription plan. Score: 0\n",
      "\n",
      "- Contract Terms: The customer does not mention the terms of the contract associated with their subscription plan. Score: 0\n",
      "\n",
      "- Data or Usage Limits: The customer does not discuss data or usage limits included in their subscription plan. Score: 0\n",
      "\n",
      "- Plan Comparison: The customer does not ask for a comparison between different subscription plans. Score: 0\n",
      "\n",
      "- Billing Cycle Related to Plan: The customer does not discuss how billing cycles work in relation to their subscription plan. Score: 0\n",
      "\n",
      "- Promotional Offers: The customer inquires about a promotional offer that has expired, which is directly related to their subscription plan. Score: 1\n",
      "\n",
      "- Total Score: The conversation scores 2 out of 10, which is below the threshold of 5 or higher for a subscription plan clarification issue.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": subscription_plan},\n",
    "    {\"role\": \"assistant\", \"content\": json.dumps(cc['conversation'])},\n",
    "    {\"role\": \"user\", \"content\": \"Give your reasoning and add points to finally end the response with a score. Your response should be in text giving a 1 or 0 for each rubric.\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:05:05.873422Z",
     "iopub.status.busy": "2024-05-28T13:05:05.872824Z",
     "iopub.status.idle": "2024-05-28T13:05:05.879309Z",
     "shell.execute_reply": "2024-05-28T13:05:05.878329Z",
     "shell.execute_reply.started": "2024-05-28T13:05:05.873388Z"
    }
   },
   "outputs": [],
   "source": [
    "network_issue = \"\"\"\n",
    "Rubric to Assess if the Conversation is About a Phone Network Issue\n",
    "\n",
    "Network Connectivity: The conversation includes a discussion about problems with network connectivity (e.g., no signal, dropped calls).\n",
    "\n",
    "Score 1 if present.\n",
    "Data Service Issues: The customer mentions issues with mobile data services (e.g., slow data speeds, unable to access the internet).\n",
    "\n",
    "Score 1 if present.\n",
    "Coverage Problems: The conversation involves the customer reporting poor coverage or dead zones in specific locations.\n",
    "\n",
    "Score 1 if present.\n",
    "Signal Strength: The customer inquires about or mentions weak or fluctuating signal strength.\n",
    "\n",
    "Score 1 if present.\n",
    "Network Outages: The conversation includes a discussion about network outages or disruptions.\n",
    "\n",
    "Score 1 if present.\n",
    "Call Quality: The customer mentions issues with call quality (e.g., echo, static, poor voice clarity).\n",
    "\n",
    "Score 1 if present.\n",
    "Roaming Issues: The conversation involves problems with roaming services (e.g., unable to connect to networks while traveling).\n",
    "\n",
    "Score 1 if present.\n",
    "SIM Card Problems: The customer reports issues related to the SIM card (e.g., not recognized by the device, needing replacement).\n",
    "\n",
    "Score 1 if present.\n",
    "Network Settings: The conversation includes the agent guiding the customer through adjusting network settings on their device.\n",
    "\n",
    "Score 1 if present.\n",
    "Service Interference: The customer mentions potential interference affecting their network service (e.g., weather conditions, nearby construction).\n",
    "\n",
    "Score 1 if present.\n",
    "Total Score:\n",
    "\n",
    "The conversation is about a phone network issue if it scores 7 or higher out of 10.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:05:44.785139Z",
     "iopub.status.busy": "2024-05-28T13:05:44.784162Z",
     "iopub.status.idle": "2024-05-28T13:06:12.521048Z",
     "shell.execute_reply": "2024-05-28T13:06:12.519966Z",
     "shell.execute_reply.started": "2024-05-28T13:05:44.785095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Network Connectivity: The customer does not explicitly mention any issues with network connectivity, such as no signal or dropped calls. (Score: 0)\n",
      "\n",
      "Data Service Issues: The customer does not mention any problems with mobile data services, such as slow data speeds or internet access issues. (Score: 0)\n",
      "\n",
      "Coverage Problems: The customer does not discuss any specific coverage problems or dead zones in certain locations. (Score: 0)\n",
      "\n",
      "Signal Strength: The customer does not mention any issues with weak or fluctuating signal strength. (Score: 0)\n",
      "\n",
      "Network Outages: The customer does not discuss any network outages or disruptions. (Score: 0)\n",
      "\n",
      "Call Quality: The customer does not mention any issues with call quality, such as echo, static, or poor voice clarity. (Score: 0)\n",
      "\n",
      "Roaming Issues: The customer does not mention any problems with roaming services while traveling. (Score: 0)\n",
      "\n",
      "SIM Card Problems: The customer does not report any issues related to the SIM card, such as it not being recognized by the device or needing a replacement. (Score: 0)\n",
      "\n",
      "Network Settings: The customer does not mention any guidance or issues related to adjusting network settings on their device. (Score: 0)\n",
      "\n",
      "Service Interference: The customer does not mention any potential interference affecting their network service, such as weather conditions or nearby construction. (Score: 0)\n",
      "\n",
      "Total Score: Since the customer's conversation does not address any of the specific issues listed in the rubric, the total score is 0 out of 10.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": network_issue},\n",
    "    {\"role\": \"assistant\", \"content\": json.dumps(get_json(df.loc[1,\"Conversation\"])[\"conversation\"])},\n",
    "    {\"role\": \"user\", \"content\": \"Give your reasoning and add points to finally end the response with a score. Your response should be in text giving a 1 or 0 for each rubric.\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T13:08:29.158105Z",
     "iopub.status.busy": "2024-05-28T13:08:29.157361Z",
     "iopub.status.idle": "2024-05-28T13:08:58.314383Z",
     "shell.execute_reply": "2024-05-28T13:08:58.313354Z",
     "shell.execute_reply.started": "2024-05-28T13:08:29.158068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mention of Charges: The customer explicitly mentions unauthorized charges appearing on their account, which indicates a discussion about charges. Score: 1\n",
      "\n",
      "Billing Cycle References: The customer talks about charges starting appearing a few months ago, which implies a reference to a billing cycle. Score: 1\n",
      "\n",
      "Credit or Refunds: The conversation does not directly mention any credits or refunds. Score: 0\n",
      "\n",
      "Invoice or Bill Confusion: The customer expresses confusion about charges they did not authorize, which relates to their invoice or bill. Score: 1\n",
      "\n",
      "Payment Issues: The customer does not mention any issues with making a payment. Score: 0\n",
      "\n",
      "Discrepancies in Amounts: The customer talks about unauthorized devices and services, which suggests discrepancies in billed amounts. Score: 1\n",
      "\n",
      "Overcharges or Unrecognized Charges: The customer clearly states they noticed unauthorized charges, which are overcharges or unrecognized. Score: 1\n",
      "\n",
      "Promotions or Discounts Not Applied: There is no mention of promotions or discounts in the conversation. Score: 0\n",
      "\n",
      "Recurring Charges: The customer mentions unauthorized devices and services, which could imply recurring charges. Score: 1\n",
      "\n",
      "Resolution Timeline: The agent mentions that the fraud investigation team usually takes 5-7 business days to complete their review, providing a timeline for resolution. Score: 1\n",
      "\n",
      "Total Score: 8 out of 10. The conversation is about a billing issue as it scores 8 or higher out of 10.\n"
     ]
    }
   ],
   "source": [
    "# IN the above the customer has tagged it network issue but its actually a billing issue. Lets see of LLM find its.\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": assistant_message},\n",
    "    {\"role\": \"assistant\", \"content\": json.dumps(get_json(df.loc[1,\"Conversation\"])[\"conversation\"])},\n",
    "    {\"role\": \"user\", \"content\": \"Give your reasoning and add points to finally end the response with a score. Your response should be in text giving a 1 or 0 for each rubric.\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 973075,
     "sourceId": 8540256,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
